{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook contains the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch_geometric\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Parameter\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch_geometric.datasets import WikipediaNetwork, WebKB\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msidgraph\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/siddy/META/DBARC/wandb/run-20230912_124246-5gacwdj6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/sidgraph/BALL-Attention/runs/5gacwdj6\" target=\"_blank\">dry-sun-4</a></strong> to <a href=\"https://wandb.ai/sidgraph/BALL-Attention\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/sidgraph/BALL-Attention\" target=\"_blank\">https://wandb.ai/sidgraph/BALL-Attention</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/sidgraph/BALL-Attention/runs/5gacwdj6\" target=\"_blank\">https://wandb.ai/sidgraph/BALL-Attention/runs/5gacwdj6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_ball_attention = wandb.init(\n",
    "    project = \"BALL-Attention\",\n",
    "    config = {\n",
    "        \"architecture\": \"GCN+Ball-atten\",\n",
    "        \"dataset\":\"chameleon\",\n",
    "        \"epoch\": 100,\n",
    "        \"lr\": 0.001,\n",
    "        \"weight_decay\":5e-4,\n",
    "        \"Batch size\": 1,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#dataset = WebKB(root=\"/home/siddy/META/data\", name='wisconsin')\n",
    "dataset = WikipediaNetwork(root=\"/home/siddy/META/data\", name='chameleon')\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " loading planetoid datasets\n",
    "import torch_geometric.transforms as T\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2277, 2325], edge_index=[2, 36101], y=[2277], train_mask=[2277, 10], val_mask=[2277, 10], test_mask=[2277, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread SystemMonitor:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/siddy/anaconda3/envs/GDL/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/siddy/anaconda3/envs/GDL/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/siddy/.local/lib/python3.8/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 118, in _start\n",
      "    asset.start()\n",
      "  File \"/home/siddy/.local/lib/python3.8/site-packages/wandb/sdk/internal/system/assets/cpu.py\", line 166, in start\n",
      "    self.metrics_monitor.start()\n",
      "  File \"/home/siddy/.local/lib/python3.8/site-packages/wandb/sdk/internal/system/assets/interfaces.py\", line 168, in start\n",
      "    logger.info(f\"Started {self._process.name}\")\n",
      "AttributeError: 'NoneType' object has no attribute 'name'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2277])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_mask[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = to_networkx(data, to_undirected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_ball(radius: int, graph):\n",
    "    edge_dict = {}\n",
    "    for index, node in enumerate(graph.nodes()):\n",
    "        paths = nx.single_source_shortest_path(graph, node, radius)\n",
    "        if index not in edge_dict:\n",
    "            edge_dict[index] = []\n",
    "        for key, value in paths.items():\n",
    "            if len(value) == 2:\n",
    "                edge_dict[index].append(value)\n",
    "            elif len(value)==3:\n",
    "                edge_dict[index].append(value[1:])\n",
    "    return edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_dict= init_ball(radius=2, graph=G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Edge_atten(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_heads=1, concat_heads=True, alpha=0.2):\n",
    "        super().__init__()\n",
    "        self.num_heads=num_heads\n",
    "        self.concat_heads = concat_heads\n",
    "        if self.concat_heads:\n",
    "            assert out_channels % num_heads==0, \"number of output channels must be multiple of count of heads\"\n",
    "            out_channels = out_channels // num_heads\n",
    "\n",
    "        self.linear = nn.Linear(in_channels, out_channels*num_heads)\n",
    "        self.a = nn.Parameter(torch.Tensor(num_heads, 2*out_channels))\n",
    "        self.leakyrelu = nn.LeakyReLU(alpha)\n",
    "\n",
    "        #xavier uniform initialization\n",
    "        nn.init.xavier_uniform_(self.linear.weight.data, gain=1.414)\n",
    "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
    "    \n",
    "    def forward(self, node_feats, edge_index):\n",
    "        node_feats = torch.unsqueeze(node_feats, dim=0)\n",
    "        batch_size, num_nodes = node_feats.size(0), node_feats.size(1)\n",
    "        node_feats = self.linear(node_feats)\n",
    "        node_feats = node_feats.view(batch_size, num_nodes, self.num_heads, -1)\n",
    "        node_feats_flat = node_feats.view(batch_size*num_nodes, self.num_heads, -1)\n",
    "        edge_indices_row = edge_index[0]\n",
    "        edge_indices_col = edge_index[1]\n",
    "        a_input = torch.cat([\n",
    "            torch.index_select(input=node_feats_flat, index=edge_indices_row, dim=0),\n",
    "            torch.index_select(input=node_feats_flat, index=edge_indices_col, dim=0)\n",
    "        ], dim=-1)\n",
    "        attn_logits = torch.einsum('bhc, hc->bh', a_input, self.a)\n",
    "        attn_logits = self.leakyrelu(attn_logits)\n",
    "        attn_probs = F.softmax(attn_logits, dim=-2)\n",
    "        return attn_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread SystemMonitor:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/siddy/anaconda3/envs/GDL/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/siddy/anaconda3/envs/GDL/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/siddy/.local/lib/python3.8/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 118, in _start\n",
      "    asset.start()\n",
      "  File \"/home/siddy/.local/lib/python3.8/site-packages/wandb/sdk/internal/system/assets/cpu.py\", line 166, in start\n",
      "    self.metrics_monitor.start()\n",
      "  File \"/home/siddy/.local/lib/python3.8/site-packages/wandb/sdk/internal/system/assets/interfaces.py\", line 168, in start\n",
      "    logger.info(f\"Started {self._process.name}\")\n",
      "AttributeError: 'NoneType' object has no attribute 'name'\n"
     ]
    }
   ],
   "source": [
    "class BallGCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='add')\n",
    "        self.lin = Linear(in_channels, out_channels, bias=False)\n",
    "        self.bias = Parameter(torch.empty(out_channels))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "        self.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight:None):\n",
    "        # what is the shape of inpur x ? - needed [N, in_channels]\n",
    "        # edge indices shape needed is [2, E]\n",
    "\n",
    "        #add self_loops to the adjacency matrix, how to give num nodes?\n",
    "        #edge_index, _ = add_self_loops(edge_index)\n",
    "        #print(edge_index)\n",
    "        # linearly transform node feature matrix\n",
    "        x = self.lin(x)\n",
    "        #x = torch.index_select(input=x, index=edge_index[0], dim=0)\n",
    "        # x_ball = torch.cat([torch.index_select(input=x, index=edge_index[0], dim=0), NOTE THAT IT WILL GIVE INDEX OUT OF RANGE ONE OPTION IS TO GO WITH REINDEXING\n",
    "        #             torch.index_select(input=x, index=edge_index[1], dim=0)],dim=0)\n",
    "        #compute normalization\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt==float('inf')] = 0\n",
    "        #print(deg_inv_sqrt.shape)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        # propagating messages\n",
    "        out = self.propagate(edge_index, x=x, edge_weight=edge_weight, norm=norm)\n",
    "        out = torch.index_select(input=out, index=min(edge_index[0]), dim=0) #NOTE TRICK IS TO PICK MIN EDGE INDEX AS IT WILL CORRESPOND TO THE CENTER NODE OF THE BALL\n",
    "        # bias\n",
    "        out += self.bias\n",
    "        return torch.squeeze(out)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j has shape [E, out_channels]\n",
    "        # normalize node features\n",
    "        return norm.view(-1,1) *x_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BallGCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = BallGCNConv(in_channels, hidden_channels)\n",
    "        self.fc = Linear(hidden_channels, out_channels)\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.fc(self.conv1(x, edge_index, edge_weight))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_attn = Edge_atten(in_channels=data.x.size(1), out_channels=64)\n",
    "ball_gcn = BallGCN(in_channels=data.x.size(1), hidden_channels=64, out_channels=dataset.num_classes)\n",
    "msg = nn.Linear(in_features=data.x.size(1), out_features=dataset.num_classes, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(set(edge_attn.parameters())| set(ball_gcn.parameters()) | set(msg.parameters()), lr=0.001, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    edge_attn.train()\n",
    "    ball_gcn.train()\n",
    "    feats = []\n",
    "    for node, ball in edge_dict.items():\n",
    "        if len(ball)<1:\n",
    "            index_feat = msg(data.x[node])\n",
    "            #print(index_feat)\n",
    "            #print(index_feat.shape)\n",
    "            # np.vstack((feats, np.array(index_feat.detach())))\n",
    "            feats.append(index_feat)\n",
    "        else:\n",
    "            edge_list = torch.permute(torch.tensor(ball, dtype=torch.long), (1,0))\n",
    "            attn_probs = edge_attn(data.x, edge_list)\n",
    "            out = ball_gcn(data.x, edge_list, attn_probs)\n",
    "            # print(out)\n",
    "            # print(out.shape)\n",
    "            # np.vstack((feats, np.array(out.detach())))\n",
    "            feats.append(out)\n",
    "    feat = torch.stack(feats, -2)\n",
    "    #print(feat)\n",
    "    print(feat.shape)\n",
    "    loss = F.cross_entropy(feat[data.train_mask[:,0]], data.y[data.train_mask[:,0]])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test():\n",
    "    edge_attn.eval()\n",
    "    ball_gcn.eval()\n",
    "    feats = []\n",
    "    for node, ball in edge_dict.items():\n",
    "        if len(ball)<1:\n",
    "            index_feat = msg(data.x[node]).argmax(dim=-1)\n",
    "            feats.append(index_feat)\n",
    "        else:\n",
    "            edge_list = torch.permute(torch.tensor(ball, dtype=torch.long), (1,0))\n",
    "            attn_probs = edge_attn(data.x, edge_list)\n",
    "            out = ball_gcn(data.x, edge_list, attn_probs).argmax(dim=-1)\n",
    "            feats.append(out)\n",
    "    feat = torch.stack(feats, -1)\n",
    "    print(feat.shape)\n",
    "    accs=[]\n",
    "    for mask in [data.train_mask[:,0], data.val_mask[:,0], data.test_mask[:,0]]:\n",
    "        accs.append(int((feat[mask] == data.y[mask]).sum()) / int(mask.sum()))\n",
    "    return accs   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import time\n",
    "epochs=100\n",
    "best_val_acc = final_test_acc = 0\n",
    "times = []\n",
    "for epoch in range(1, epochs+1):\n",
    "    start = time.time()\n",
    "    loss= train()\n",
    "    wandb.log({\"Loss\":loss})\n",
    "    train_acc, val_acc, tmp_test_acc = test()\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        test_acc = tmp_test_acc\n",
    "    print(f\"Epoch:{epoch}, Loss:{loss}, Train:{train_acc}, Val:{val_acc}, Test:{test_acc}\")\n",
    "    wandb.log({\"train_acc\":train_acc})\n",
    "    wandb.log({\"test_acc\":test_acc})\n",
    "    wandb.log({\"val_acc\":val_acc})\n",
    "    times.append(time.time()-start)\n",
    "print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>█▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁▂▂▂▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄██████████████</td></tr><tr><td>train_acc</td><td>▁▂▃▃▇███████████████████████████████████</td></tr><tr><td>val_acc</td><td>▁▃▃▄▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆██████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss</td><td>1.10178</td></tr><tr><td>test_acc</td><td>0.60784</td></tr><tr><td>train_acc</td><td>0.525</td></tr><tr><td>val_acc</td><td>0.55</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neat-moon-3</strong> at: <a href=\"https://wandb.ai/sidgraph/BALL-Attention/runs/din8oame\" target=\"_blank\">https://wandb.ai/sidgraph/BALL-Attention/runs/din8oame</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230912_104914-din8oame/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_ball_attention.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (GDL)",
   "language": "python",
   "name": "gdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
